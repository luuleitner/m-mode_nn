# ========================================
# COMPREHENSIVE TRAINING CONFIGURATION
# ========================================

# Global Settings
global_setting:
  run:
    type: embedding                   # embedding, classifier
    mode: run                         # debug, run, overfit
    behaviour: deterministic          # deterministic, probabilistic
    device: cuda                      # cpu, cuda

    config:
      debug:
        level: 2                      # 1, 2, 3
      deterministic:
        seed: &global_seed 353

  paths:
    base_data_path: &base_data_path "/vol/data/2026_wristus_wiicontroller_sgambato"
    process_base_data_path: &process_base_data_path "/vol/data/2026_wristus_wiicontroller_sgambato/processed"
    train_base_data_path: &train_base_data_path "/vol/data/2026_wristus_wiicontroller_sgambato/processed/Dataset_Envelope_CNN/Window18_Stride02_Labels_soft/latest"

# ========================================
# ML PIPELINE CONFIGURATION
# ========================================
ml:
  # Data Loading
  loading:
    load_data_pickle: false

  # =====================================================================
  # DATASET CONFIGURATION - DATA SAMPLING PIPELINE
  # =====================================================================
  #
  #  ┌─────────────────────────────────────────────────────────────────┐
  #  │  H5 FILES (from preprocessing)                                 │
  #  └──────────────────────────┬──────────────────────────────────────┘
  #                             │
  #                             ▼
  #  ┌─────────────────────────────────────────────────────────────────┐
  #  │  STEP 1: GLOBAL FILTERS (reduce dataset before splitting)      │
  #  │          Applied with AND logic to ALL data                    │
  #  └──────────────────────────┬──────────────────────────────────────┘
  #                             │
  #                             ▼
  #  ┌─────────────────────────────────────────────────────────────────┐
  #  │  STEP 2: TEST/VAL SELECTION (strategy: "filter" or "random")   │
  #  │          Select which data goes to test/val                    │
  #  └──────────────────────────┬──────────────────────────────────────┘
  #                             │
  #                             ▼
  #  ┌─────────────────────────────────────────────────────────────────┐
  #  │  STEP 3: SPLIT TEST/VAL (ratio + level)                        │
  #  │          Divide selected data into test and val sets           │
  #  └──────────────────────────┬──────────────────────────────────────┘
  #                             │
  #                             ▼
  #  ┌─────────────────────────────────────────────────────────────────┐
  #  │  STEP 4: TRAIN = REMAINDER (+ shuffling)                       │
  #  │          Everything not in test/val becomes training           │
  #  └─────────────────────────────────────────────────────────────────┘
  #
  dataset:
    # --- Data Source ---
    data_root: *train_base_data_path
    target_batch_size: &target_batch_size 50
    dataset_key: 'token'
    random_seed: *global_seed

    # =========================================
    # STEP 1: GLOBAL FILTERS
    # =========================================
    # Applied to ALL data BEFORE any splitting.
    # Use to reduce dataset (e.g., exclude bad sessions).
    # Filters combine with AND logic.
    global_participant_filter: null         # e.g., [1, 2, 3] - keep only these
    global_session_filter: null             # e.g., [14, 15] - keep only these
    global_experiment_filter: null          # e.g., [0, 1, 2] - keep only these
    global_label_filter: null               # e.g., [1, 2] - keep only movement

    # =========================================
    # STEP 2: TEST/VAL SELECTION STRATEGY
    # =========================================
    # Choose ONE strategy: "filter" or "random"
    test_val_strategy: "random"

    # --- Option A: FILTER strategy ---
    # Select test/val by matching criteria (AND logic)
    test_val_participant_filter: null       # e.g., [1, 2]
    test_val_session_filter: null           # e.g., [14] - session 14 for test/val
    test_val_experiment_filter: null        # e.g., [5, 6, 7]
    test_val_label_filter: null             # e.g., [1, 2]

    # --- Option B: RANDOM strategy ---
    # Randomly select N experiments for test/val
    test_val_random_experiments: 3          # Number of experiments to select
    test_val_multi_session: true            # Prefer experiments from different sessions

    # =========================================
    # STEP 3: TEST/VAL SPLIT
    # =========================================
    test_val_split_ratio: 0.5               # 0.5 = 50% test, 50% val
    split_level: "experiment"               # "sequence" or "experiment"

    # =========================================
    # STEP 4: SHUFFLING (for training)
    # =========================================
    shuffle_experiments: true               # Randomize experiment order
    shuffle_sequences: true                 # Randomize sequence order within experiments

    # =========================================
    # STEP 5: CLASS BALANCING (train set only)
    # =========================================
    # Balances class distribution by oversampling minority classes.
    # Majority class (0) appears exactly once, minority classes (1, 2)
    # are oversampled with augmentation to match majority count.
    balance_classes: true                   # Enable balanced batch construction
    balance_strategy: "oversample"          # oversample | undersample

    oversample_config:
      method: "augment"                     # duplicate | augment | mixed
      target_ratio: 1.0                     # 1.0 = match majority class count
      augment_ratio: 0.5                    # For 'mixed': ratio of augmented vs duplicated

      # Augmentation settings (semantically preserving transforms)
      augmentations:
        noise:
          enabled: true
          std: 0.02                         # Gaussian noise standard deviation
        scale:
          enabled: true
          range: [0.9, 1.1]                 # Amplitude scaling range
        shift:
          enabled: true
          max_shift: 3                      # Max temporal shift in samples

  # Model Architecture
  model:
    type: "UNetAutoencoder"           # "CNNAutoencoder", "UNetAutoencoder", "TransformerAutoencoder"
    channels_per_layer: [32, 64, 128, 256]  # 4 levels for U-Net
    embedding_dim: 512                # Less aggressive compression
    num_heads: 8                   # For transformer models
    num_layers: 4                  # For transformer models

  # =====================================================================
  # CLASSIFIER CONFIGURATION (for embedding-based classification)
  # =====================================================================
  classifier:
    type: "XGBoost"
    class_names: ["noise", "upward", "downward"]

    # XGBoost hyperparameters
    xgboost:
      n_estimators: 50
      max_depth: 6
      learning_rate: 0.1
      subsample: 0.8
      colsample_bytree: 0.8
      reg_alpha: 0.0
      reg_lambda: 1.0
      early_stopping_rounds: 20

    # Embedding preprocessing
    preprocessing:
      normalize_embeddings: true
      scaler: "standard"              # standard | minmax | none

    # Hyperparameter tuning (optional)
    hyperparameter_search:
      enabled: false
      method: "optuna"                # optuna | grid | random
      n_trials: 50

  # =====================================================================
  # CNN CLASSIFIER CONFIGURATION (end-to-end classification)
  # =====================================================================
  # Alternative to AE + XGBoost: direct CNN classification
  # Run with: python -m src.training.train_cnn_classifier --config config/config.yaml
  classifier_cnn:
    channels: [32, 64, 128, 256]      # Encoder channels (same as UNet)
    hidden_dim: 256                    # Classification head hidden dimension
    num_classes: 3                     # noise, upward, downward
    dropout: 0.5                       # Dropout rate for regularization
    epochs: 500                        # Training epochs
    learning_rate: 0.0001              # Learning rate

  # Training Configuration
  training:
    # Basic Training Parameters
    epochs: 150
    lr: 0.0001
    weight_decay: 1e-4

    # Optimizer Configuration
    optimizer:
      type: "adamw"                   # adamw, adam, sgd
      betas: [0.9, 0.999]            # For Adam/AdamW
      eps: 1e-8                      # For Adam/AdamW
      momentum: 0.9                  # For SGD

    # Learning Rate Scheduler
    lr_scheduler:
      type: "cosine"                  # plateau, onecycle, cosine, step, none
      factor: 0.5                    # ReduceLROnPlateau factor
      patience: 10                   # ReduceLROnPlateau patience
      threshold: 1e-4                # ReduceLROnPlateau threshold
      min_lr: 1e-6                   # Minimum learning rate

    # Loss Configuration
    loss_weights:
      mse_weight: 0.5
      l1_weight: 0.5                  # More L1 = sharper reconstructions
      embedding_reg: 0.0005

    # Training Regularization
    regularization:
      grad_clip_norm: 1.0            # Gradient clipping norm
      dropout_rate: 0.0              # Dropout rate (if applicable)
      batch_norm: true               # Use batch normalization

    # Class Balancing at Training Time
    class_balancing:
      enabled: true                  # Enable weighted loss
      method: "weighted_loss"        # weighted_loss

    # Checkpointing
    checkpointing:
      save_best: true
      save_every_n_epochs: 10        # Save regular checkpoint every N epochs
      checkpoint_path: *train_base_data_path

    # Restart Configuration
    restart:
      enable: true
      save_restart_every: 10         # Save restart checkpoint every N epochs

    # Validation and Evaluation
    validation:
      plot_every_n_epochs: 1         # Generate plots every N epochs

# ========================================
# PREPROCESSING CONFIGURATION
# ========================================
preprocess:
  data:
    basepath: *base_data_path
    id: "Dataset_Envelope_CNN"
    strategy: "all"                   # all | selection_file
    selection_file: "/vol/data/2026_wristus_wiicontroller_sgambato/raw/day002/selection_20260129_202647.csv"   # Used when strategy=selection_file (run utils/generate_selection.py)
    save_ftype: "h5"                  # h5, zarr

  signal:
    bandpass:
      apply: true
      lowcut: 8e6                     # 8 MHz
      highcut: 12e6                   # 12 MHz
      fs: 50e6                        # 50 MSPS
      order: 10
    tgc:
      apply: true
      freq: 50e6                      # 50 MSPS
      coef_att: 0.3                   # Attenuation coefficient in dB/(MHz·cm) - 0.5 is the standard for soft tissue, adjust as needed
    clip:
      apply: true
      initial_size: 1996
      samples2remove_start: 107
      samples2remove_end: 589             
    envelope:
      apply: true
      interp: false
      padding:
        apply: true
        mode: "constant"
        amount: 30
    logcompression:
      apply: true
      db: 45
    normalization:
      apply: true
      method: "peakZ"
      minmax_path: "/home/cleitner/code/lab/projects/ML/m-mode_nn/config/minmax_Envdata.csv"
    decimation:
      apply: true
      factor: 10                      # 50MSPS -> 5MSPS

  tokenization:
    tokens2file: true
    startendID: false
    window: 18
    stride: 2
    description: "Specifies the tokenization process."

  sequencing:
    window: 15

  output:
    mode: "flat"             # transformer | flat (flat for CNN, no sequencing)

  # Label configuration is in a separate file for clarity
  label_config: "preprocessing/label_logic/label_config.yaml"

# ========================================
# LOGGING CONFIGURATION
# ========================================
wandb:
  use_wandb: true
  project: "m-mode_nn_embedding"
  api_key: "c1842818a3c8db66c3f75d77b4640749e64cdc0d"
  name: "embedding_autoencoder"
  notes: "1DCNN for dimensionality reduction with comprehensive restart support"
  tags:
    - "embedding"
    - "autoencoder"
    - "ultrasound"
    - "restart_enabled"

  # Advanced WandB settings
  settings:
    save_code: true
    log_gradients: false             # Log gradient histograms
    log_parameters: false            # Log parameter histograms
    watch_model: true                # Watch model with wandb.watch()

# ========================================
# EXPERIMENTAL CONFIGURATION
# ========================================
experiment:
  name: "ultrasound_embedding_v1"
  description: "1DCNN autoencoder for ultrasound M-mode dimensionality reduction"
  version: "1.0.0"

  # Reproducibility
  reproducibility:
    deterministic_algorithms: true    # Use deterministic algorithms when possible
    benchmark_mode: false            # CUDNN benchmark mode

  # Resource Management
  resources:
    num_workers: 2                   # DataLoader workers
    pin_memory: true                 # Pin memory for faster GPU transfer
    prefetch_factor: 2               # DataLoader prefetch factor

# ========================================
# ADVANCED TRAINING OPTIONS
# ========================================
advanced:
  # Mixed Precision Training
  mixed_precision:
    enable: false                    # Enable AMP (Automatic Mixed Precision)
    loss_scale: "dynamic"            # dynamic or float value

  # Distributed Training
  distributed:
    enable: false                    # Enable distributed training
    backend: "nccl"                  # nccl, gloo
    world_size: 1                    # Number of processes

  # Profiling
  profiling:
    enable: false                    # Enable PyTorch profiler
    trace_file: "trace.json"         # Profiler output file