# ========================================
# COMPREHENSIVE TRAINING CONFIGURATION
# ========================================

# Global Settings
global_setting:
  run:
    type: embedding                   # embedding, classifier
    mode: run                         # debug, run, overfit
    behaviour: deterministic          # deterministic, probabilistic
    device: cuda                      # cpu, cuda

    config:
      debug:
        level: 2                      # 1, 2, 3
      deterministic:
        seed: &global_seed 33

  paths:
    base_data_path: &base_data_path "/vol/data/2026_wristus_wiicontroller_sgambato/day002"
    process_base_data_path: &process_base_data_path "/vol/data/2026_wristus_wiicontroller_sgambato/day002/processed"
    train_base_data_path: &train_base_data_path "/vol/data/2026_wristus_wiicontroller_sgambato/day002/processed/Dataset_Envelope_CNN/Window15_Stride05_Labels_soft/run_20260201_105509"


# ========================================
# PREPROCESSING CONFIGURATION
# ========================================
preprocess:
  data:
    basepath: *base_data_path
    id: "Dataset_Envelope_CNN"
    strategy: "all"                   # all | selection_file
    selection_file: null              # Used when strategy=selection_file (run utils/generate_selection.py)
    save_ftype: "h5"                  # h5, zarr

  signal:
    clip:
      apply: true
      initial_size: 1996
      samples2remove_start: 107
      samples2remove_end: 589
    tgc:
      apply: true
      freq: 50e6                      # 50 MSPS
      coef_att: 0.3                   # Attenuation coefficient in dB/(MHz·cm) - 0.5 is the standard for soft tissue, adjust as needed
    bandpass:
      apply: true
      lowcut: 8e6                     # 8 MHz
      highcut: 12e6                   # 12 MHz
      fs: 50e6                        # 50 MSPS
      order: 10
    envelope:
      apply: true
      interp: false
      padding:
        apply: true
        mode: "constant"
        amount: 30
      # Anti-aliasing lowpass before decimation
      lowpass:
        apply: true
        mode: "auto"                    # auto | manual
        # Auto mode: cutoff = 0.8 * (fs / decimation_factor / 2) = 0.4 * fs / D
        # For D=10: 2 MHz, D=5: 4 MHz, D=2: 10 MHz
        manual_cutoff: 2e6              # Used only when mode="manual"
        order: 4
    decimation:
      apply: true
      factor: 10                      # 50MSPS -> 5MSPS
    logcompression:
      apply: true
      db: 50
    normalization:
      apply: true
      method: "peak"

    # Temporal differentiation (gradient along pulse/slow-time axis)
    differentiation:
      apply: true                  # Set to true to use differentiated signal
      method: "gradient"            # gradient | diff
                                    # gradient: np.gradient (central differences, same length)
                                    # diff: np.diff (forward differences, length-1)
      order: 1                      # 1 = first derivative (velocity)
                                    # 2 = second derivative (acceleration)

  tokenization:
    tokens2file: true
    startendID: false
    window: 15
    stride: 5
    description: "Specifies the tokenization process."

  sequencing:
    window: 15

  output:
    mode: "flat"             # transformer | flat (flat for CNN, no sequencing)

  # Label configuration is in a separate file for clarity
  label_config: "preprocessing/label_logic/label_config.yaml"


# ========================================
# ML PIPELINE CONFIGURATION
# ========================================
ml:
  # =====================================================================
  # DATASET CONFIGURATION - DATA SAMPLING PIPELINE
  # =====================================================================
  # Data Loading
  loading:
    load_data_pickle: false
  #
  #  ┌─────────────────────────────────────────────────────────────────┐
  #  │  H5 FILES (from preprocessing)                                 │
  #  └──────────────────────────┬──────────────────────────────────────┘
  #                             │
  #                             ▼
  #  ┌─────────────────────────────────────────────────────────────────┐
  #  │  STEP 1: GLOBAL FILTERS (reduce dataset before splitting)      │
  #  │          Applied with AND logic to ALL data                    │
  #  └──────────────────────────┬──────────────────────────────────────┘
  #                             │
  #                             ▼
  #  ┌─────────────────────────────────────────────────────────────────┐
  #  │  STEP 2: TEST/VAL SELECTION (strategy: "filter" or "random")   │
  #  │          Select which data goes to test/val                    │
  #  └──────────────────────────┬──────────────────────────────────────┘
  #                             │
  #                             ▼
  #  ┌─────────────────────────────────────────────────────────────────┐
  #  │  STEP 3: SPLIT TEST/VAL (ratio + level)                        │
  #  │          Divide selected data into test and val sets           │
  #  └──────────────────────────┬──────────────────────────────────────┘
  #                             │
  #                             ▼
  #  ┌─────────────────────────────────────────────────────────────────┐
  #  │  STEP 4: TRAIN = REMAINDER (+ shuffling)                       │
  #  │          Everything not in test/val becomes training           │
  #  └─────────────────────────────────────────────────────────────────┘
  #
  dataset:
    # --- Data Source ---
    data_root: *train_base_data_path
    target_batch_size: &target_batch_size 250
    dataset_key: 'token'
    random_seed: *global_seed

    # =========================================
    # STEP 1: GLOBAL FILTERS
    # =========================================
    # Applied to ALL data BEFORE any splitting.
    # Use to reduce dataset (e.g., exclude bad sessions).
    # Filters combine with AND logic.
    global_participant_filter: null         # e.g., [1, 2, 3] - keep only these
    global_session_filter: null             # e.g., [14, 15] - keep only these
    global_experiment_filter: null          # e.g., [0, 1, 2] - keep only these
    global_label_filter: null               # e.g., [1, 2, 3, 4] - keep only movement
    # NOTE: global_label_filter is auto-set to [1,2,3,4] when include_noise=false
    #       in preprocessing/label_logic/label_config.yaml

    # =========================================
    # STEP 2: TEST/VAL SELECTION STRATEGY
    # =========================================
    # Choose ONE strategy: "filter" or "random"
    test_val_strategy: "random"

    # --- Option A: FILTER strategy ---
    # Select test/val by matching criteria (AND logic)
    test_val_participant_filter: null       # e.g., [1, 2]
    test_val_session_filter: null           # e.g., [14] - session 14 for test/val
    test_val_experiment_filter: null        # e.g., [5, 6, 7]
    test_val_label_filter: null             # e.g., [1, 2]

    # --- Option B: RANDOM strategy ---
    # Randomly select experiments for test/val
    test_val_random_experiments: 0.2        # Count (>=1) or percentage (0-1), e.g., 3 or 0.1 for 10%
    test_val_multi_session: true            # Prefer experiments from different sessions

    # =========================================
    # STEP 3: TEST/VAL SPLIT
    # =========================================
    test_val_split_ratio: 0.5               # 0.5 = 50% test, 50% val
    split_level: "experiment"               # "sequence" or "experiment"

    # =========================================
    # STEP 4: SHUFFLING (for training)
    # =========================================
    shuffle_experiments: true               # Randomize experiment order
    shuffle_sequences: true                 # Randomize sequence order within experiments

    # =========================================
    # STEP 5: CLASS BALANCING (train set only)
    # =========================================
    # Two options: dataset-level (oversampling) OR loss-level (weighted loss)
    # For joint AE+classification: use weighted loss to preserve real 90/5/5 distribution
    balance_classes: false                  # Disabled: using weighted loss instead
    balance_strategy: "oversample"          # (unused when balance_classes=false)

    oversample_config:
      method: "augment"                     # duplicate | augment | mixed
      target_ratio: 0.2                     # 1.0 = match majority class count
      augment_ratio: 0.3                    # For 'mixed': ratio of augmented vs duplicated

      # Augmentation settings (semantically preserving transforms)
      augmentations:
        noise:
          enabled: true
          std: 0.02                         # Gaussian noise standard deviation
        scale:
          enabled: true
          range: [0.9, 1.1]                 # Amplitude scaling range
        shift:
          enabled: true
          max_shift: 3                      # Max temporal shift in samples


  # =====================================================================
  # UNET CONFIGURATION (Multihead Classifier)
  # =====================================================================
  model:
    type: "UNetAutoencoder"           # "CNNAutoencoder", "UNetAutoencoder", "TransformerAutoencoder"
    channels_per_layer: [16, 32, 64]       # 3 levels (preserves temporal dim=2 at bottleneck)
    embedding_dim: 128                # Less aggressive compression
    num_heads: 8                   # For transformer models
    num_layers: 4                  # For transformer models

  # =====================================================================
  # XGB CLASSIFIER CONFIGURATION (for embedding-based classification)
  # =====================================================================
  classifier:
    type: "XGBoost"
    # NOTE: class_names should be loaded from preprocessing/label_logic/label_config.yaml
    # This hardcoded list is deprecated and should be removed in favor of dynamic loading.
    class_names: ["noise", "up", "down", "left", "right"]

    # XGBoost hyperparameters
    xgboost:
      n_estimators: 300              # More trees, early stopping finds optimum
      max_depth: 6
      learning_rate: 0.05            # Lower LR + more trees = better generalization
      subsample: 0.8
      colsample_bytree: 0.8
      reg_alpha: 0.1                 # Light L1 regularization
      reg_lambda: 1.0
      min_child_weight: 3            # Prevents overfitting on small leaves
      gamma: 0.1                     # Minimum loss reduction for split
      early_stopping_rounds: 30      # More patience for convergence

    # Embedding preprocessing
    preprocessing:
      normalize_embeddings: true
      scaler: "standard"              # standard | minmax | none

    # Hyperparameter tuning (optional)
    hyperparameter_search:
      enabled: false
      method: "optuna"                # optuna | grid | random
      n_trials: 50

  # =====================================================================
  # CNN CLASSIFIER CONFIGURATION (DirectCNNClassifier)
  # =====================================================================
  cnn:
    # Width multiplier: scales channel counts
    #   1 = 16→32→64 channels,  ~48K params (default, lightweight)
    #   2 = 32→64→128 channels, ~187K params (recommended, similar to USMModeCNN)
    #   4 = 64→128→256 channels, ~740K params (large)
    width_multiplier: 1

  # =====================================================================
  # TRAINING CONFIGURATION
  # =====================================================================
  training:
    # Basic Training Parameters
    epochs: 200
    lr: 0.0001                        # Lower LR to reduce overfitting (was 0.0003)
    weight_decay: 0.02                # Stronger weight decay for regularization (was 0.01)

    # Optimizer Configuration
    optimizer:
      type: "adamw"                   # adamw, adam, sgd
      betas: [0.9, 0.999]            # For Adam/AdamW
      eps: 1e-8                      # For Adam/AdamW
      momentum: 0.9                  # For SGD

    # Learning Rate Scheduler
    lr_scheduler:
      type: "cosine"                  # plateau, onecycle, cosine, step, none

    # Loss Configuration
    loss_weights:
      mse_weight: 0.3
      l1_weight: 0.3                  # More L1 = sharper reconstructions
      embedding_reg: 0.0005
      classification_weight: 0.4     # Joint classification loss (balanced with reconstruction)

    # Training Regularization
    regularization:
      grad_clip_norm: 1.0            # Gradient clipping norm
      batch_norm: true               # Use batch normalization
      dropout:
        spatial: 0.2                 # Dropout2d between conv blocks (0.1-0.2 recommended)
        fc: 0.6            # Dropout in FC classifier head (0.3-0.5 recommended)

    # Class Imbalance Handling
    imbalance:
      class_weights:
        enabled: true                 # Enable class weighting in loss function

        # Weighting method: how to compute weights from class counts
        #   - inverse_frequency: weight = total / (n_classes * count)  [standard, recommended]
        #   - effective_samples: weight = (1 - β^n) / (1 - β), β=0.999  [from "Class-Balanced Loss" paper]
        #   - sqrt_inverse: weight = sqrt(total / count)  [less aggressive than inverse]
        #   - custom: use custom_weights below
        method: "inverse_frequency"

        # Power scaling: adjusts how aggressively minority classes are weighted
        #
        # Given class distribution: Noise=90%, Movement=2.5% each (ratio ~36:1)
        # Base inverse weights before power: Noise≈0.03, Movement≈1.0
        #
        #   power=0.5 (sqrt):  Noise=0.17, Move=1.0  → 6x difference   (gentle, may underfit minority)
        #   power=1.0 (linear): Noise=0.03, Move=1.0  → 33x difference  (standard, balanced)
        #   power=1.5 (aggressive): Noise=0.005, Move=1.0 → 200x difference (risks instability)
        #
        # Rule of thumb:
        #   - power < 1.0: Use when minority classes have noisy labels or you want smoother training
        #   - power = 1.0: Standard choice, theoretically optimal for clean labels
        #   - power > 1.0: Use when minority classes are critical and you accept some majority degradation
        power: 1.1

        # Custom weights (only used when method="custom")
        # Order: [Noise, Up, Down, Left, Right]
        custom_weights: null          # e.g., [0.1, 1.0, 1.0, 1.0, 1.0]

    # Checkpointing
    checkpointing:
      save_best: true
      save_every_n_epochs: 5        # Save regular checkpoint every N epochs
      checkpoint_path: *train_base_data_path

    # Restart Configuration
    restart:
      enable: true
      save_restart_every: 5         # Save restart checkpoint every N epochs

    # Validation and Evaluation
    validation:
      plot_every_n_epochs: 2         # Generate plots every N epochs

    # Early Stopping
    early_stopping:
      enabled: true                  # Enable early stopping
      patience: 15                   # Epochs to wait for improvement (was 25)
      min_delta: 0.001               # Minimum change to count as improvement (0.1% for balanced_accuracy)
      monitor: "val_balanced_accuracy"   # Metric to monitor: val_loss, val_accuracy, val_balanced_accuracy


# ========================================
# CROSS-VALIDATION CONFIGURATION
# ========================================
# For K-fold cross-validation experiments.
# Use: python -m src.data.precompute_kfolds --config config/config.yaml
#
# This creates multiple fold directories, each with train_ds.pkl, val_ds.pkl, test_ds.pkl
# The regular precompute_datasets.py creates a single split (non-CV mode).
#
cross_validation:
  output_subdir: "cv_folds"             # Folds saved to: {data_root}/{output_subdir}/fold_X/

  # =========================================
  # CV STRATEGY (choose one)
  # =========================================
  # Options:
  #   - "experiment_kfold": K-fold over experiments within selected participant(s)
  #   - "session_loso":     Leave-One-Session-Out
  #   - "participant_lopo":   Leave-One-Participant-Out (cross-subject generalization)
  #   - "participant_within": Within-participant modeling (subject-specific, no cross-subject)
  strategy: "participant_within"

  # =========================================
  # STRATEGY 1: experiment_kfold
  # =========================================
  # K-fold cross-validation over experiments within specific participant(s).
  # Use case: Evaluate model on same participant(s) with different experiment splits.
  #
  # Example: participant_filter=[1], n_folds=5
  #   Participant 1 has 10 experiments → each fold holds out 2 experiments
  #
  experiment_kfold:
    participant_filter: null           # Which participant(s) to include [1,2] or null=all
    session_filter: null                # Optionally filter sessions too
    n_folds: 5                          # Number of folds
    test_val_split_ratio: 0.5           # Within holdout: 50% test, 50% val

  # =========================================
  # STRATEGY 2: session_loso
  # =========================================
  # Leave-One-Session-Out cross-validation.
  # Use case: Evaluate generalization across recording sessions.
  #
  # Example: 4 sessions → 4 folds, each holds out one session
  #
  session_loso:
    participant_filter: null            # Which participant(s) to include (null=all)
    session_filter: null                # Which sessions to fold over (null=all available)
    test_val_split_ratio: 0.5           # Within holdout session: 50% test, 50% val

  # =========================================
  # STRATEGY 3: participant_lopo
  # =========================================
  # Leave-One-Participant-Out cross-validation.
  # Use case: Evaluate generalization to new participants.
  #
  # Example: 3 participants → 3 folds, each holds out one participant
  #
  participant_lopo:
    participant_filter: null            # Which participants to fold over (null=all)
    test_val_split_ratio: 0.5           # Within holdout participant: 50% test, 50% val

  # =========================================
  # STRATEGY 4: participant_within
  # =========================================
  # Within-participant cross-validation (subject-specific modeling).
  # Each fold trains/val/tests on ONE participant's data independently.
  #
  # Use cases:
  #   - Personalized models per subject
  #   - Identify which subjects are easier/harder to classify
  #   - Debug data quality issues per subject
  #   - Establish upper bound before attempting cross-subject generalization
  #
  # Example: 4 participants → 4 folds
  #   Fold 0: Train/val/test on Participant 1's data only
  #   Fold 1: Train/val/test on Participant 2's data only
  #   ...
  #   Aggregated: Compare performance across participants
  #
  participant_within:
    participant_filter: all            # "all", null, single ID, or list of IDs [0, 1, 2]
    train_ratio: 0.8                   # 80% of each participant's experiments for training
    test_val_split_ratio: 0.5          # Of remaining 20%: 50% val, 50% test


# ========================================
# LOGGING CONFIGURATION
# ========================================
wandb:
  use_wandb: true
  project: "IEEE SAS 2026"
  api_key: "c1842818a3c8db66c3f75d77b4640749e64cdc0d"
  name: "embedding_autoencoder"
  notes: "1DCNN for dimensionality reduction with comprehensive restart support"
  tags:
    - "embedding"
    - "autoencoder"
    - "ultrasound"
    - "restart_enabled"

  # Advanced WandB settings
  settings:
    save_code: true
    log_gradients: false             # Log gradient histograms
    log_parameters: false            # Log parameter histograms
    watch_model: true                # Watch model with wandb.watch()

# ========================================
# EXPERIMENTAL CONFIGURATION
# ========================================
experiment:
  name: "ultrasound_embedding_v1"
  description: "1DCNN autoencoder for ultrasound M-mode dimensionality reduction"
  version: "1.0.0"

  # Reproducibility
  reproducibility:
    deterministic_algorithms: true    # Use deterministic algorithms when possible
    benchmark_mode: false            # CUDNN benchmark mode

  # Resource Management
  resources:
    num_workers: 8                   # DataLoader workers
    pin_memory: true                 # Pin memory for faster GPU transfer
    prefetch_factor: 4               # DataLoader prefetch factor

# ========================================
# ADVANCED TRAINING OPTIONS
# ========================================
advanced:
  # Mixed Precision Training
  mixed_precision:
    enable: false                    # Enable AMP (Automatic Mixed Precision)
    loss_scale: "dynamic"            # dynamic or float value

  # Distributed Training
  distributed:
    enable: false                    # Enable distributed training
    backend: "nccl"                  # nccl, gloo
    world_size: 1                    # Number of processes

  # Profiling
  profiling:
    enable: false                    # Enable PyTorch profiler
    trace_file: "trace.json"         # Profiler output file