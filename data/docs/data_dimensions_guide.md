# Data Dimensions Guide

## Document Information
- **Version**: Auto-generated
- **Updated**: 2025-10-22 23:32:56
- **Generated by**: dimension_checker.py
- **Purpose**: Complete guide to understanding data dimensions throughout the processing pipeline

---

## Current Configuration

### Processing Parameters
```yaml
clip_enabled: True
clip_samples: 1300
decimation_enabled: True
decimation_factor: 10
envelope_enabled: True
logcompression_enabled: False
normalization_enabled: True
token_window: 5
token_stride: 2
sequence_window: 10
startend_markers: False
```

---

## Data Flow & Dimension Transformations

### Processing Pipeline Dimensions

### 1. Raw
- **Shape**: `[3, 65000, 5000]` (3 × 65000 × 5000)
- **Description**: Raw ultrasound data

### 2. After Clipping
- **Shape**: `[3, 1300, 5000]` (3 × 1300 × 5000)
- **Description**: Clipped to 1300 samples

### 3. After Decimation
- **Shape**: `[3, 130, 5000]` (3 × 130 × 5000)
- **Description**: Decimated by factor 10

### 4. After Tokenization
- **Shape**: `[2498, 3, 130, 5]` (2498 × 3 × 130 × 5)
- **Description**: Tokenized with window=5, stride=2
- **Number of tokens**: 2498
- **Token overlap**: 3 samples

### 5. After Sequencing
- **Shape**: `[249, 10, 3, 130, 5]` (249 × 10 × 3 × 130 × 5)
- **Description**: Sequenced with window=10
- **Number of sequences**: 249
- **Tokens clipped**: 8 (don't fit into sequences)

---

## Memory Usage

- **Total elements per experiment**: 4,855,500
- **Memory per experiment**: 18.52 MB (float32)
- **Memory formula**: `num_sequences × sequence_window × channels × height × width × 4 bytes`

---

## Actual Data Dimensions (From Processed Files)

### Sample File: `P0006/S0019_P0006_E0009_Xy.h5`


### Metadata Statistics
- **Total tokens**: 1347520
- **Unique sequences**: 586
- **Unique experiments**: 24

---

## Dimension Calculation Formulas

```python
# Number of tokens
num_tokens = (signal_length - token_window) // token_stride + 1

# Number of sequences  
num_sequences = num_tokens // sequence_window

# Height after clipping
height_clipped = samples2keep if clip_flag else original_height

# Height after decimation
height_decimated = height_clipped // decimation_factor

# Height with markers
height_with_markers = height + 2 if startend_markers else height

# Final output shape
output_shape = [num_sequences, sequence_window, channels, height_final, token_window]
```

---

## Loading Processed Data

### Python Example
```python
import h5py
import numpy as np

# Load single experiment
with h5py.File('processed_file.h5', 'r') as f:
    data = f['X'][:]  # Shape: [num_sequences, 10, 3, height, 5]
    labels = f['y'][:]  # Shape: [num_sequences, 10, 1]
    
# For PyTorch
import torch
data_tensor = torch.from_numpy(data).float()
label_tensor = torch.from_numpy(labels).long()
```

### Expected Shapes by Stage
1. **After loading**: `[num_sequences, 10, 3, height, 5]`
2. **After batching**: `[batch_size, num_sequences, 10, 3, height, 5]`
3. **For model input**: Depends on model architecture

---

## Validation Checklist

- [ ] Config token_window matches data width dimension
- [ ] Config sequence_window matches second dimension 
- [ ] Height dimension accounts for decimation factor
- [ ] Height includes +2 if start/end markers enabled
- [ ] Number of sequences × sequence_window ≤ total tokens
- [ ] Metadata CSV row count matches expected tokens

---

## Common Issues and Solutions

### 1. Dimension Mismatch in Model
**Problem**: Model expects different input shape
**Solution**: Check if start/end markers are consistently enabled/disabled

### 2. Memory Errors During Training
**Problem**: Out of memory errors
**Solution**: Reduce batch size or sequence_window

### 3. Tokens Don't Fit Into Sequences
**Problem**: Many tokens are clipped
**Solution**: Adjust token_stride or sequence_window for better fit

---

*This guide is automatically generated and updated by `dimension_checker.py`*
